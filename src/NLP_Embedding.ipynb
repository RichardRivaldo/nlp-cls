{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnDHJdq_xTYS"
      },
      "source": [
        "# Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvNnXBoGtujX",
        "outputId": "1be9b15d-de2e-4b3f-f10e-25c9ed66351e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WZOOsTjHrYp5"
      },
      "outputs": [],
      "source": [
        "root_path = \"drive/MyDrive/IF/Sem7/NLP/2/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6RkIvAUxaec",
        "outputId": "54ee00f8-a3d9-46b0-c76a-5f1dd3233b0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Sastrawi in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow_text in /usr/local/lib/python3.7/dist-packages (2.10.0)\n",
            "Requirement already satisfied: tensorflow<2.11,>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (2.10.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (0.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (1.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (4.1.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (0.26.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (1.21.6)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (1.15.0)\n",
            "Requirement already satisfied: keras<2.11,>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (2.10.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (1.14.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (21.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (57.4.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (1.1.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (2.10.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (3.1.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (3.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (1.48.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (0.4.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (2.0.7)\n",
            "Requirement already satisfied: tensorboard<2.11,>=2.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (2.10.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.11,>=2.10.0->tensorflow_text) (14.0.6)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow<2.11,>=2.10.0->tensorflow_text) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.11,>=2.10.0->tensorflow_text) (1.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (1.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (2022.6.15)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow_text) (3.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow<2.11,>=2.10.0->tensorflow_text) (3.0.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: glove-python-binary in /usr/local/lib/python3.7/dist-packages (0.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from glove-python-binary) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from glove-python-binary) (1.7.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras_tuner in /usr/local/lib/python3.7/dist-packages (1.1.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras_tuner) (2.23.0)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.7/dist-packages (from keras_tuner) (1.0.4)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras_tuner) (2.10.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras_tuner) (7.9.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras_tuner) (21.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras_tuner) (1.21.6)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.7/dist-packages (from ipython->keras_tuner) (0.18.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython->keras_tuner) (2.0.10)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras_tuner) (2.6.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->keras_tuner) (57.4.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras_tuner) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras_tuner) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython->keras_tuner) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras_tuner) (5.1.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras_tuner) (4.4.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython->keras_tuner) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras_tuner) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras_tuner) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras_tuner) (3.0.9)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras_tuner) (0.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras_tuner) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras_tuner) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras_tuner) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras_tuner) (2022.6.15)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras_tuner) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras_tuner) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras_tuner) (0.37.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras_tuner) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras_tuner) (1.35.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras_tuner) (3.17.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras_tuner) (1.2.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras_tuner) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras_tuner) (1.8.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras_tuner) (1.48.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras_tuner) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras_tuner) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras_tuner) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras_tuner) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras_tuner) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras_tuner) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras_tuner) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras_tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras_tuner) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install Sastrawi\n",
        "! pip install tensorflow_text\n",
        "! pip install glove-python-binary\n",
        "! pip install keras_tuner --upgrade"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6PIAzYIprXn"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "O3IJiszkpsm5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras_tuner as kt\n",
        "from glove import Corpus, Glove\n",
        "import tensorflow_text as tftext\n",
        "from tensorflow.ragged import constant\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.initializers import Constant\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.metrics import Accuracy, Precision, Recall\n",
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
        "from tensorflow.keras.layers import Embedding, Dropout, Bidirectional, LSTM, Dense, InputLayer, LeakyReLU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ju34JZGxpl_J"
      },
      "source": [
        "# Data + Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdMSXSbMMldr"
      },
      "source": [
        "## Reading the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6Rp8bMUczhb-"
      },
      "outputs": [],
      "source": [
        "def tokenize(sent):\n",
        "    tokens = sent.split()\n",
        "    tokens = list(filter(lambda token: len(token) > 1, tokens))\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WbnWurKKlmue"
      },
      "outputs": [],
      "source": [
        "# Split label and features\n",
        "def split_dataframe(df):\n",
        "    df_features = df.loc[:, \"text_a\"].str.lower()\n",
        "\n",
        "    factory = StopWordRemoverFactory()\n",
        "    stopword = factory.create_stop_word_remover()\n",
        "\n",
        "    df_features = df_features.apply(lambda x: stopword.remove(x))\n",
        "    df_features = df_features.apply(lambda x: tokenize(x))\n",
        "\n",
        "    return df_features, df.loc[:, \"label\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goitV2xylDsH"
      },
      "source": [
        "### Training Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ZOVk9gxapm-g",
        "outputId": "94e90127-e42f-4c00-e5c0-dfb3ebd2f5e2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  text_a label\n",
              "0      betewe buka twitter cuman ngetweet liat home b...    no\n",
              "1      mas piyuuu mugo2 corona tuh mulut tersumpal ma...    no\n",
              "2      e100ss gini buka informasi sejelas nya identit...   yes\n",
              "3      neng solo wes ono terduga corona cobo neng ati...    no\n",
              "4      midiahn nii akun gak takut takut nya isu coron...    no\n",
              "...                                                  ...   ...\n",
              "21596  depok panas ga karuan kereta sampe pasming huj...    no\n",
              "21597  oxfara arie kriting yg lebi goblo nya orang ke...    no\n",
              "21598  virus corona menyaba depok cuci tangan makan n...    no\n",
              "21599  mata sipit tinggal depok udah abis dah bahan c...    no\n",
              "21600       i ak batuk pilek pusing demam anjir ak depok    no\n",
              "\n",
              "[21601 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dd2e1339-32e2-4750-a4cb-9b4e916b2162\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_a</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>betewe buka twitter cuman ngetweet liat home b...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mas piyuuu mugo2 corona tuh mulut tersumpal ma...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>e100ss gini buka informasi sejelas nya identit...</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neng solo wes ono terduga corona cobo neng ati...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>midiahn nii akun gak takut takut nya isu coron...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21596</th>\n",
              "      <td>depok panas ga karuan kereta sampe pasming huj...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21597</th>\n",
              "      <td>oxfara arie kriting yg lebi goblo nya orang ke...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21598</th>\n",
              "      <td>virus corona menyaba depok cuci tangan makan n...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21599</th>\n",
              "      <td>mata sipit tinggal depok udah abis dah bahan c...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21600</th>\n",
              "      <td>i ak batuk pilek pusing demam anjir ak depok</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>21601 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd2e1339-32e2-4750-a4cb-9b4e916b2162')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dd2e1339-32e2-4750-a4cb-9b4e916b2162 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dd2e1339-32e2-4750-a4cb-9b4e916b2162');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df_train = pd.read_csv(f\"{root_path}train.csv\")\n",
        "df_train.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tCOk_uw0l0Fr"
      },
      "outputs": [],
      "source": [
        "X_train, y_train = split_dataframe(df_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8U21tRcVlGMK"
      },
      "source": [
        "### Validation Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ZbfbV84DqJmx",
        "outputId": "b6e9362e-810f-49fc-cd5c-46be39d5e7d0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 text_a label\n",
              "0                               jek dajal ga depok bang    no\n",
              "1     detikcom untung depok masuk wilayah nya ridwan...    no\n",
              "2     df dom jakarta depok yg gunain vc cabang nya c...    no\n",
              "3                                     your2rl depok jkt    no\n",
              "4     doakan indonesia selamat virus corona pkb depo...   yes\n",
              "...                                                 ...   ...\n",
              "2795  ku tenang2 bae ku sih ya corona nya ga depok k...    no\n",
              "2796  guru hati hati ya virus corona uda indonesia t...   yes\n",
              "2797  4 terawan menyebut virus corona indonesia terd...   yes\n",
              "2798        realffk buhari can t pronounce corona virus    no\n",
              "2799  hadapi wabah corona pemuda muhammadiyah pemeri...   yes\n",
              "\n",
              "[2800 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-338f03cd-ad59-4508-bf5d-4a884f828c80\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_a</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>jek dajal ga depok bang</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>detikcom untung depok masuk wilayah nya ridwan...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>df dom jakarta depok yg gunain vc cabang nya c...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>your2rl depok jkt</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>doakan indonesia selamat virus corona pkb depo...</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2795</th>\n",
              "      <td>ku tenang2 bae ku sih ya corona nya ga depok k...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2796</th>\n",
              "      <td>guru hati hati ya virus corona uda indonesia t...</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2797</th>\n",
              "      <td>4 terawan menyebut virus corona indonesia terd...</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2798</th>\n",
              "      <td>realffk buhari can t pronounce corona virus</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2799</th>\n",
              "      <td>hadapi wabah corona pemuda muhammadiyah pemeri...</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2800 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-338f03cd-ad59-4508-bf5d-4a884f828c80')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-338f03cd-ad59-4508-bf5d-4a884f828c80 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-338f03cd-ad59-4508-bf5d-4a884f828c80');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df_val = pd.read_csv(f\"{root_path}dev.csv\")\n",
        "df_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "x3dtkb8rnS6x"
      },
      "outputs": [],
      "source": [
        "X_val, y_val = split_dataframe(df_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCGq-tFolH4g"
      },
      "source": [
        "### Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "cuhcnhGfro_l",
        "outputId": "486a9f79-5214-44ec-ddca-8513c1049f60"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 text_a label\n",
              "0                               jek dajal ga depok bang    no\n",
              "1     detikcom untung depok masuk wilayah nya ridwan...    no\n",
              "2     df dom jakarta depok yg gunain vc cabang nya c...    no\n",
              "3                                     your2rl depok jkt    no\n",
              "4     doakan indonesia selamat virus corona pkb depo...   yes\n",
              "...                                                 ...   ...\n",
              "2795  ku tenang2 bae ku sih ya corona nya ga depok k...    no\n",
              "2796  guru hati hati ya virus corona uda indonesia t...   yes\n",
              "2797  4 terawan menyebut virus corona indonesia terd...   yes\n",
              "2798        realffk buhari can t pronounce corona virus    no\n",
              "2799  hadapi wabah corona pemuda muhammadiyah pemeri...   yes\n",
              "\n",
              "[2800 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-733fd5b1-4a99-4a3e-8f21-2b95316a71b4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_a</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>jek dajal ga depok bang</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>detikcom untung depok masuk wilayah nya ridwan...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>df dom jakarta depok yg gunain vc cabang nya c...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>your2rl depok jkt</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>doakan indonesia selamat virus corona pkb depo...</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2795</th>\n",
              "      <td>ku tenang2 bae ku sih ya corona nya ga depok k...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2796</th>\n",
              "      <td>guru hati hati ya virus corona uda indonesia t...</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2797</th>\n",
              "      <td>4 terawan menyebut virus corona indonesia terd...</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2798</th>\n",
              "      <td>realffk buhari can t pronounce corona virus</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2799</th>\n",
              "      <td>hadapi wabah corona pemuda muhammadiyah pemeri...</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2800 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-733fd5b1-4a99-4a3e-8f21-2b95316a71b4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-733fd5b1-4a99-4a3e-8f21-2b95316a71b4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-733fd5b1-4a99-4a3e-8f21-2b95316a71b4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "df_test = pd.read_csv(f\"{root_path}test.csv\")\n",
        "df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "TZlWEcNVryQk"
      },
      "outputs": [],
      "source": [
        "X_test, y_test = split_dataframe(df_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GL-HQqH2MpgF"
      },
      "source": [
        "## EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGEKeDYxMsg_",
        "outputId": "d600ddab-d96b-4201-ad99-a012854a90b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15.61811953150317"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Mencari panjang rata-rata dari kalimat yang ada\n",
        "df_train[\"text_a\"].apply(lambda x: len(x.split())).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kh3V0FqfFsAq"
      },
      "source": [
        "# Glove Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xtTpVM-r_Lf"
      },
      "source": [
        "Pada tugas kali ini, penulis sebelumnya berencana untuk mencoba membangun *word embeddings vector* sendiri dengan menggunakan *corpus* yang didapat dari Wikipedia Indonesia. Namun, penulis tidak bisa menemukan berkas-berkas yang dibutuhkan oleh GloVe untuk membangun *embeddings* tersebut. Selain itu, OS yang dimiliki penulis tidak kompatibel dan tidak mampu menjalankan *script* yang digunakan oleh GloVe dalam membangun *embeddings* tersebut."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ygwdu2WxLjx"
      },
      "source": [
        "Pendekatan lain yang pernah penulis lakukan sebelumnya adalah dengan membangun *embeddings* sendiri dengan menggunakan pustaka GloVe Python. Hal ini dapat dilakukan dengan menggunakan teks yang ada sebagai masukan untuk pembangunan *embeddings* dengan menggunakan kode program berikut."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "LV-N2M2iMOoG"
      },
      "outputs": [],
      "source": [
        "def create_corpus(tokens, window=20):\n",
        "  # Instantiate the corpus\n",
        "  c = Corpus()\n",
        "\n",
        "  # Create the occurence matrix with context window of 20\n",
        "  # Context window is the technique of counting co-occurence\n",
        "  # 20 means that we will count co-occurence 20 words left-right\n",
        "  # The number is chosen because average maximum words for the dataset is approx. 15\n",
        "  c.fit(tokens, window)\n",
        "  \n",
        "  return c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "FdhBc8LKQbIK"
      },
      "outputs": [],
      "source": [
        "# Embed the corpus into GloVe Model\n",
        "# Components are the numbers of latent vector dimension\n",
        "# Learning Rate is the SGD Learning Rate\n",
        "# Epochs is the number of training epochs for fitting the corpus\n",
        "# Number of threads is the number of threads used in training the data\n",
        "def embed_glove(c, num_of_components=100, lr=0.05, epochs=50, num_of_threads=30):\n",
        "  # Instantiate the model\n",
        "  glove = Glove(no_components=num_of_components, learning_rate=lr)\n",
        "\n",
        "  # Fit over the co-occurence matrix in the corpus\n",
        "  glove.fit(c.matrix, epochs=epochs, no_threads=num_of_threads)\n",
        "\n",
        "  # Add the vocab of corpus to the model\n",
        "  glove.add_dictionary(c.dictionary)\n",
        "\n",
        "  return glove"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "yXD87W8XDnqC"
      },
      "outputs": [],
      "source": [
        "# Flatten list of list of tokens\n",
        "def flatten_tokens(lol_tokens):\n",
        "    return [t for lot in lol_tokens for t in lot]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ioIr03ozej3Y"
      },
      "outputs": [],
      "source": [
        "# Using Tensorflow Keras Tokenizer API\n",
        "# The tokenizer will take all preprocessed tokens from before\n",
        "def construct_tokenizer(tokens, lower_text=False):\n",
        "  # Create the tokenizer with specialized Out of Vocabulary Token\n",
        "  tokenizer = Tokenizer(lower=lower_text, oov_token=\"<OOV>\")\n",
        "\n",
        "  # Fit the tokenizer into the tokens\n",
        "  tokenizer.fit_on_texts(tokens)\n",
        "\n",
        "  # Avoid out of range index when doing embedding lookup\n",
        "  for i in tokenizer.word_index:\n",
        "    tokenizer.word_index[i] = tokenizer.word_index[i] - 1\n",
        "\n",
        "  return tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "IMa50F_YhSZc"
      },
      "outputs": [],
      "source": [
        "def generate_embed_matrix(embeddings, tokenizer):\n",
        "  # Get the word index and number of tokens from the tokenizer\n",
        "  word_index = tokenizer.word_index\n",
        "  # Already included the OOV word\n",
        "  num_of_tokens = len(word_index)\n",
        "\n",
        "  # Get embeddings model dimension (length of each word vector)\n",
        "  embeddings_dim = embeddings.no_components\n",
        "\n",
        "  # Initialize numpy matrix of zeros as the embeddings matrix\n",
        "  # The dimension will be the number of tokens x the embeddings dimension\n",
        "  embeddings_matrix = np.zeros((num_of_tokens, embeddings_dim))\n",
        "\n",
        "  # Iterate over all words in the word index\n",
        "  for word, i in word_index.items():\n",
        "    # Get the word index in the GloVe dictionary\n",
        "    glove_word_index = embeddings.dictionary.get(word)\n",
        "    if glove_word_index is not None:\n",
        "      # Get the embeddings vector of the corresponding GloVe index\n",
        "      embeddings_vector = embeddings.word_vectors[glove_word_index]\n",
        "      embeddings_matrix[i] = embeddings_vector\n",
        "\n",
        "  return embeddings_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1gjDaME3r3Z"
      },
      "source": [
        "# Feature-Label Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQx_K7ZZAAvE"
      },
      "source": [
        "## Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "V7UtKGmw2aTQ"
      },
      "outputs": [],
      "source": [
        "# Rejoin all tokens back into a sentence\n",
        "def rejoin_sentences(tokens):\n",
        "  return ' '.join(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "sIar8oEP3wL6"
      },
      "outputs": [],
      "source": [
        "# Converting feature texts into sequence using Keras Tokenizer corpus\n",
        "def convert_to_seq(df, tokenizer):\n",
        "    df = df.apply(lambda x: rejoin_sentences(x))\n",
        "    return tokenizer.texts_to_sequences(df.to_list())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "rLOkZiEo42xZ"
      },
      "outputs": [],
      "source": [
        "# Generating features into Ragged Tensor\n",
        "def generate_features(df, tokenizer):\n",
        "    seqs = convert_to_seq(df, tokenizer)\n",
        "    return constant(seqs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnpq1Ii8ADCM"
      },
      "source": [
        "## Label Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "apwovWUO-6nW"
      },
      "outputs": [],
      "source": [
        "def fit_encoder(df):\n",
        "    label_encoder = LabelEncoder()\n",
        "    label_encoder.fit(df)\n",
        "\n",
        "    return label_encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "_CCc2XiT8moj"
      },
      "outputs": [],
      "source": [
        "def generate_labels(df, encoder):\n",
        "    df_labels = encoder.transform(df)\n",
        "    n_class = len(np.unique(df_labels))\n",
        "    return df_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_Lu2kt8cqo7"
      },
      "source": [
        "# Modelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "vSuQ1UGBcveX"
      },
      "outputs": [],
      "source": [
        "def construct_model(hp):\n",
        "    # Get global model properties\n",
        "    vocab_size = len(tokenizer.word_index)      # Number of tokens or vocabularies\n",
        "    embeddings_dim = glove.no_components        # The dimension of embeddings matrix vector\n",
        "\n",
        "    hp_units = hp.Int('units', min_value=32, max_value=128, step=32)\n",
        "    hp_dropout = hp.Choice('dropout', values=[2e-1, 4e-1])\n",
        "    hp_lr = hp.Float(\"learning_rate\", min_value=1e-3, max_value=1e-2, sampling=\"log\")\n",
        "\n",
        "    # Initialize the Sequential Model\n",
        "    seq_model = Sequential([\n",
        "        # Initialize Ragged Input Layer\n",
        "        InputLayer(input_shape=(None, ), ragged=True),\n",
        "        # Convert the layer into densely-connected layer\n",
        "        tftext.keras.layers.ToDense(pad_value=0, mask=True),\n",
        "        # Inititalize Embedding Layer with weighted embeddings matrix\n",
        "        Embedding(vocab_size, embeddings_dim, embeddings_initializer=Constant(embeddings_matrix), weights=[embeddings_matrix]),\n",
        "        # Bidirectional LSTM\n",
        "        # Bidirectional here means that the LSTM can do two-way learning\n",
        "        # Return Sequences because there are still many layers needing it\n",
        "        Bidirectional(LSTM(hp_units, return_sequences=True)),\n",
        "        # Dropout Regularization\n",
        "        Dropout(hp_dropout),\n",
        "        # One directional LSTM layer\n",
        "        LSTM(hp_units),\n",
        "        # Transform the output with Leaky ReLU\n",
        "        LeakyReLU(),\n",
        "        # Add last dense layer with specified Activation Function\n",
        "        Dense(1, \"sigmoid\", kernel_regularizer=l2(0.01))],\n",
        "        name=\"nlp-non-ctx\")\n",
        "    \n",
        "    seq_model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=hp_lr), metrics=[\"accuracy\", Precision(), Recall()])\n",
        "\n",
        "    return seq_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "tMpmYc9EURjr"
      },
      "outputs": [],
      "source": [
        "def create_tuner():\n",
        "    tuner = kt.Hyperband(construct_model,\n",
        "                         objective='val_accuracy',\n",
        "                         max_epochs=4,\n",
        "                         factor=3,\n",
        "                         directory='models',\n",
        "                         project_name='nlp-non-ctx')\n",
        "    \n",
        "    cb = EarlyStopping(monitor='val_loss', patience=5)\n",
        "\n",
        "    return tuner, cb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "nCib9-9PVf9P"
      },
      "outputs": [],
      "source": [
        "def execute_tuning(tuner, cb, X_train, y_train, X_val, y_val, epochs=2):\n",
        "    tuner.search(X_train, y_train, epochs=epochs, validation_data=(X_val, y_val), callbacks=[cb])\n",
        "    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "    return tuner, best_hps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "A5AfqFL0Iy8f"
      },
      "outputs": [],
      "source": [
        "def show_model_summary(model):\n",
        "    model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "bDlu_9OQ-mUm"
      },
      "outputs": [],
      "source": [
        "# Create and train the hyper model\n",
        "def fit_train(tuner, best_hps, X_train, y_train, X_val, y_val, epochs=10):\n",
        "    hypermodel = tuner.hypermodel.build(best_hps)\n",
        "    history = hypermodel.fit(X_train, y_train, epochs=epochs, validation_data=(X_val, y_val))\n",
        "    \n",
        "    val_acc_per_epoch = history.history['val_accuracy']\n",
        "    best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
        "\n",
        "    hypermodel = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "    # Retrain the model\n",
        "    hypermodel.fit(X_train, y_train, epochs=best_epoch, validation_data=(X_val, y_val))\n",
        "\n",
        "    return hypermodel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "r4gX6ngpeH6e"
      },
      "outputs": [],
      "source": [
        "def eval_model(hypermodel, X_test, y_test):\n",
        "    hypermodel.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVr3kB7mCSjw"
      },
      "source": [
        "# Execution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbRbKZesZCJ5"
      },
      "source": [
        "## Generate GloVe Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "CLuH-uCsf6BH"
      },
      "outputs": [],
      "source": [
        "tokens = X_train.to_list()\n",
        "corpus = create_corpus(tokens)\n",
        "glove = embed_glove(corpus)\n",
        "flattened_tokens = flatten_tokens(tokens)\n",
        "tokenizer = construct_tokenizer(flattened_tokens)\n",
        "embeddings_matrix = generate_embed_matrix(glove, tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewWU51YQY2qp"
      },
      "source": [
        "## Data Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "kMLxlauzBObL"
      },
      "outputs": [],
      "source": [
        "X_train = generate_features(X_train, tokenizer)\n",
        "label_encoder = fit_encoder(y_train)\n",
        "y_train = generate_labels(y_train, label_encoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "4gBTm3xfZGsL"
      },
      "outputs": [],
      "source": [
        "X_val = generate_features(X_val, tokenizer)\n",
        "y_val = generate_labels(y_val, label_encoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Rppe2esGZLnb"
      },
      "outputs": [],
      "source": [
        "X_test = generate_features(X_test, tokenizer)\n",
        "y_test = generate_labels(y_test, label_encoder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLTn_jtlY8gP"
      },
      "source": [
        "## Hyperparameter Tuning + Training + Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wn2Ae8VrY8Np",
        "outputId": "27bb75b8-0dd7-4254-a39f-7cf7a728c920"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 09m 31s]\n",
            "val_accuracy: 0.8657143115997314\n",
            "\n",
            "Best val_accuracy So Far: 0.866428554058075\n",
            "Total elapsed time: 00h 56m 31s\n"
          ]
        }
      ],
      "source": [
        "tuner, cb = create_tuner()\n",
        "tuner, best_hps = execute_tuning(tuner, cb, X_train, y_train, X_val, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqnTJbMbTTR7",
        "outputId": "4f75d688-2d1c-4975-8a63-eca48f6d20c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "676/676 [==============================] - 143s 201ms/step - loss: 0.4113 - accuracy: 0.8264 - precision_1: 0.7015 - recall_1: 0.6686 - val_loss: 0.3462 - val_accuracy: 0.8686 - val_precision_1: 0.7620 - val_recall_1: 0.6973\n",
            "Epoch 2/10\n",
            "676/676 [==============================] - 136s 201ms/step - loss: 0.2442 - accuracy: 0.9195 - precision_1: 0.8635 - recall_1: 0.8486 - val_loss: 0.4268 - val_accuracy: 0.8446 - val_precision_1: 0.6744 - val_recall_1: 0.7440\n",
            "Epoch 3/10\n",
            "676/676 [==============================] - 131s 194ms/step - loss: 0.1754 - accuracy: 0.9474 - precision_1: 0.9004 - recall_1: 0.9146 - val_loss: 0.4812 - val_accuracy: 0.8171 - val_precision_1: 0.6148 - val_recall_1: 0.7383\n",
            "Epoch 4/10\n",
            "676/676 [==============================] - 138s 204ms/step - loss: 0.1163 - accuracy: 0.9702 - precision_1: 0.9519 - recall_1: 0.9420 - val_loss: 0.5068 - val_accuracy: 0.8121 - val_precision_1: 0.6049 - val_recall_1: 0.7383\n",
            "Epoch 5/10\n",
            "676/676 [==============================] - 134s 199ms/step - loss: 0.0944 - accuracy: 0.9782 - precision_1: 0.9666 - recall_1: 0.9558 - val_loss: 0.4857 - val_accuracy: 0.8407 - val_precision_1: 0.6928 - val_recall_1: 0.6634\n",
            "Epoch 6/10\n",
            "676/676 [==============================] - 135s 200ms/step - loss: 0.0750 - accuracy: 0.9826 - precision_1: 0.9696 - recall_1: 0.9688 - val_loss: 0.5668 - val_accuracy: 0.7921 - val_precision_1: 0.5718 - val_recall_1: 0.7044\n",
            "Epoch 7/10\n",
            "676/676 [==============================] - 132s 195ms/step - loss: 0.0616 - accuracy: 0.9852 - precision_1: 0.9708 - recall_1: 0.9770 - val_loss: 0.6716 - val_accuracy: 0.7879 - val_precision_1: 0.5637 - val_recall_1: 0.7072\n",
            "Epoch 8/10\n",
            "676/676 [==============================] - 146s 216ms/step - loss: 0.0488 - accuracy: 0.9877 - precision_1: 0.9738 - recall_1: 0.9829 - val_loss: 0.6243 - val_accuracy: 0.7564 - val_precision_1: 0.5116 - val_recall_1: 0.7765\n",
            "Epoch 9/10\n",
            "676/676 [==============================] - 137s 203ms/step - loss: 0.0424 - accuracy: 0.9886 - precision_1: 0.9728 - recall_1: 0.9872 - val_loss: 0.6463 - val_accuracy: 0.7886 - val_precision_1: 0.5640 - val_recall_1: 0.7171\n",
            "Epoch 10/10\n",
            "676/676 [==============================] - 131s 194ms/step - loss: 0.0382 - accuracy: 0.9896 - precision_1: 0.9728 - recall_1: 0.9910 - val_loss: 0.6680 - val_accuracy: 0.7918 - val_precision_1: 0.5714 - val_recall_1: 0.7016\n",
            "676/676 [==============================] - 138s 195ms/step - loss: 0.4716 - accuracy: 0.7734 - precision_2: 0.6028 - recall_2: 0.5750 - val_loss: 0.3971 - val_accuracy: 0.8379 - val_precision_2: 0.6712 - val_recall_2: 0.7016\n"
          ]
        }
      ],
      "source": [
        "# Train model with best epoch and hyperparameters\n",
        "hypermodel = fit_train(tuner, best_hps, X_train, y_train, X_val, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tuning results\n",
        "print(best_hps.get(\"units\"))\n",
        "print(best_hps.get(\"dropout\"))\n",
        "print(best_hps.get(\"learning_rate\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBNXncf1jDQm",
        "outputId": "638df7d2-82d7-47de-8be4-a53c23cd57cd"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "96\n",
            "0.2\n",
            "0.0011980378163067161\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnBqN0sOTt0e",
        "outputId": "0b7e5154-7975-4d7f-9e6f-f23eba3dae19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "88/88 [==============================] - 4s 41ms/step - loss: 0.3971 - accuracy: 0.8379 - precision_2: 0.6712 - recall_2: 0.7016\n"
          ]
        }
      ],
      "source": [
        "# Model Evaluation\n",
        "eval_model(hypermodel, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSAnO8EKg7_n"
      },
      "source": [
        "# References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHCyhoHxg9m4"
      },
      "source": [
        "1.   https://www.tensorflow.org/tutorials/keras/keras_tuner\n",
        "2.   https://keras.io/guides/keras_tuner/getting_started/\n",
        "3.   https://keras.io/api/keras_tuner/tuners/hyperband/\n",
        "4.   https://towardsdatascience.com/sentiment-analysis-using-lstm-and-glove-embeddings-99223a87fe8e\n",
        "5.   https://rifqifai.com/membuat-model-glove-dari-korpus-wikipedia-bahasa-indonesia/\n",
        "6.   https://github.com/stanfordnlp/GloVe\n",
        "7.   https://coderzcolumn.com/tutorials/artificial-intelligence/keras-glove-embeddings-for-text-classification\n",
        "8.   https://www.kaggle.com/code/hamishdickson/bidirectional-lstm-in-keras-with-glove-embeddings/notebook\n",
        "9.   https://ksnugroho.medium.com/dasar-text-preprocessing-dengan-python-a4fa52608ffe\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "UnDHJdq_xTYS",
        "-6PIAzYIprXn",
        "ju34JZGxpl_J",
        "goitV2xylDsH",
        "8U21tRcVlGMK",
        "uCGq-tFolH4g",
        "GL-HQqH2MpgF",
        "kh3V0FqfFsAq",
        "I1gjDaME3r3Z",
        "BQx_K7ZZAAvE",
        "rnpq1Ii8ADCM",
        "L_Lu2kt8cqo7",
        "lbRbKZesZCJ5",
        "ewWU51YQY2qp",
        "RSAnO8EKg7_n"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}